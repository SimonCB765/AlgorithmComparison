PISCES code is said to be at path\to\PISCES\bin\
Python code is said to be at path\to\python\code\

containing information about the folder strucutre needed for each controller script
	Biological
	BHOSLIB
	Exact MIS
	GLP Leaf long run
	PDB
	Protein Length - generate a datasets of the lengths of all the proteins in the redudant and non-redundant datasets
	UCLUST - percentage of 'non-redudant' proteins that have an edge that wasn't removed by UCLUST

###########################################################
BHOSLIB
###########################################################
Directory Structure Expected
-----------------------------------------------------------
The BHOSLIB directory structure just consists of putting all the BHOSLIB graph files in one directory, and not changing the names.

Directory Structure Generated
-----------------------------------------------------------
After running the script the directory will contain the BHOSLIB graph files as before, but also all the results files. These are deleted on every invocation of the script.

Workflow
-----------------------------------------------------------

process for generating BHOSLIB results
	download BHOSLIB files
	run algs on them

###########################################################
Biological Datasets
###########################################################
Directory Structure Expected
-----------------------------------------------------------

Directory Structure Generated
-----------------------------------------------------------

Workflow
-----------------------------------------------------------

###########################################################
Exact MIS
###########################################################
Directory Structure Expected
-----------------------------------------------------------

Directory Structure Generated
-----------------------------------------------------------

Workflow
-----------------------------------------------------------
process for generating exact results comparison
	take Mark's results
	take the results generated by the subset comparison
	compare

###########################################################
GLP Leaf Long Run Comparison
###########################################################
Directory Structure Expected
-----------------------------------------------------------

Directory Structure Generated
-----------------------------------------------------------

Workflow
-----------------------------------------------------------

###########################################################
PDB
###########################################################
Directory Structure Expected
-----------------------------------------------------------
TopLevel
 BLASTDB
 
BLASTDB contains the files with information about similarities, resolutions etc. downloaded from PISCES
 TopLevel contains both teh BLASTDB directory and the gzipped files of the list of non-redundant proteins downloaded from PISCES

Directory Structure Generated
-----------------------------------------------------------

Workflow
-----------------------------------------------------------
process for generating PDB results
	download from PISCES
	run Leaf on the PDB info downloaded and compare

###########################################################
Protein Length
###########################################################
Directory Structure Expected
-----------------------------------------------------------

Directory Structure Generated
-----------------------------------------------------------

Workflow
-----------------------------------------------------------
to generate the histogram of lengths
	OK, a histogram (scaled to %) for length distributions in redundant set and sets returned by PISCES and Leaf, just for human proteome sounds good.
	read through the fasta file of all human sequences (in the resultsBiological)
	record the lengths of each sequence
	read through the files for each of the 10 cut offs, and record which proteins were kept by Leaf and by PISCES
	record length distributions of each

###########################################################
Protein Subset Datasets
###########################################################
Directory Structure Expected (generated by step 4 and used by step 5)
-----------------------------------------------------------
For each call of controllersubsets.py, the expected strucutre of the input path\to\results\directory\subdir directory is as follows:
	path\to\results\directory\subdir
		Dataset0
			Dataset0.fasta
			Aligned.txt
		Dataset1
			Dataset1.fasta
			Aligned.txt
		...
		DatasetN
			DatasetN.fasta
			Aligned.txt
Each Aligned.txt is the alignment file for the proteins in the dataset named by the directory that contains it.
For example, path\to\results\directory\subdir\Dataset0\Aligned.txt contains the alignments for the proteins in the dataset path\to\results\directory\subdir\Dataset0\Dataset0.fasta.
There is one sub-directory under path\to\results\directory\subdir for every dataset that the algorithms will be compared on.

Directory Structure Generated (by step 5)
-----------------------------------------------------------
The directory structure generated is the same as the expected structure (as the same directory is used for input and output).
The only additions are the results files generated by each algorithm, and the overall results files for each percentage similarity cut off.
In each path\to\results\directory\subdir\DatasetX directory, the results of culling using each algorithm at each percentage cut off are added, along with a histogram of the degree of the nodes in the graph at each percentage cut off.
In addition, one file for each percentage cut off is added under the path\to\results\directory\subdir directory. These files are named path\to\results\directory\subdir\XPercentResults.txt, where X is the percentage cut off used.
An example strucutre would be:
	path\to\results\directory\subdir
		Dataset0
			20DegreeHistogram.txt
			20LeafCull.txt
			20PISCESCull.txt
			Dataset0.fasta
			Aligned.txt
		...
		DatasetN
			20DegreeHistogram.txt
			20LeafCull.txt
			20PISCESCull.txt
			DatasetN.fasta
			Aligned.txt
		20PercentResults.txt
path\to\results\directory\subdir\Dataset0\20DegreeHistogram.txt contains the edge histogram data for the 20% similarity cut off.
path\to\results\directory\subdir\Dataset0\20LeafCull.txt contains the names of the proteins removed by the Leaf algorithm with a 20% similarity cut off.
path\to\results\directory\subdir\Dataset0\20PISCESCull.txt contains the names of the proteins removed by the PISCES algorithm with a 20% similarity cut off.
path\to\results\directory\subdir\20PercentResults.txt is a tab delimited file of the results for all N dataset and all algorithms used at 20% similarity cut off.

Workflow
-----------------------------------------------------------
If the datasets have already been generated, then skip to step 5.

1) Aquire the master file (in FASTA format) that will be used to generate the subsets.
2) BLAST the master file and create the file of alignments using PISCES.
	This uses the modified Cull_for_UserSEQ.pl PISCES file. Perform this step using the command:
		perl path\to\PISCES\bin\Cull_for_UserSEQ.pl -i path\to\FASTA\file
	As an example, assume that the FASTA file is called Human.fasta, and that the file is located at C:\Fasta\Human.fasta.
	Then the path\to\FASTA\file used would be C:\Fasta\Human, the '.fasta' at the end is removed. For any FASTA file submitted you should remove the file extension, irrespecttive of the actual extension.
3) Rename the pdbaa.align file created in the PISCES bin directory to Aligned.txt. Move the Aligned.txt file to a directory which is not the PISCES bin directory.
4) Generate the subsets of the Human.fasta file.
	The command used for this was:
		python path\to\python\code\alignmentscreatefiles.py C:\Fasta\Human.fasta path\to\Aligned.txt 100-250-500-1000-2000-5000 50-50-50-50-50-50 path\to\results\directory
	This will generate subsets of Human.fasta of 100, 250, 500, 1000, 2000 and 5000 sequences. For each of these dataset sizes, 50 datasets will be generated.
	Refer to the Directory Structure Expected section of the Protein Subset Datasets section for information on the directory structure this command generates.

At this point the datasets have all been generated, and the comparisons between the algorithms can be run.

5) Run the algorithm comparison on the sub-datasets generated.
	The command used for this was:
		python path\to\python\code\controllersubsets.py path\to\results\directory\subdir Leaf-FIS-NeighbourCull-GLP-VSA-BlastCuller-UCLUST 1
	Assuming steps 1 through 4 have been followed identically, then under the directory path\to\results\directory there should be six sub-directories.
	The names of these sub-directories will be Results100, Results250, Results500, Results1000, Results2000 and Results5000.
	path\to\results\directory\subdir should be one of these six sub-directories.
	This means that the command will have to be run once with each sub-directory if you want to compare the algorithm on all six dataset sizes.


###########################################################
UCLUST
###########################################################
Directory Structure Expected
-----------------------------------------------------------
say you generate 50 sub-datasets of 1000 proteins from the entire human proteome, and you run the redundancy removal for each sub-dataset at 3 different cut off percentages (let's say 10, 40 and 90)
 The directory structure would look like this
TopLevelDir
 10
 40
 90
in each of the sub-directories you would place one file for each sub-dataset (so 50 in total for this example)
taking 10% cutoff as an example, the files would be placed in the 10 sub-directory. For each of the 50 sub-datasets the file produced by UCLUST which contains the represetnative sequences of the clusters
 (and therefore the sequences which should be non-redudnant) should be put into the sub-directory. For example, the sequences which represent the clusters generated by running UCLUST on sub-dataset 00
at a 10% sequence identitiy cutoff would be placed in sub-directoy 10, those generated by ruinning UCLUST on the dataset at 40% cutoff would be placed in sub-directory 40.
 The naming of the files of representative sequences does not matter. Any name is fine for the individual files.

Directory Structure Generated
-----------------------------------------------------------
After running the script the directory is not modified, and the results are put in the file you specifiy when calling the script.

Workflow
-----------------------------------------------------------

import gzip
import os
import sys

import sparsematrix
import CMLeaf

def main(i, locForResults, dirPISCES, duplicates, resolutionData, fastaSequences, alignmentFile, minLength=20, maxLength=10000):
    """Compares the non-redundant dataset produced by Leaf under given parameters, with the one generated by PISCES.

    @param i: The gzipped list of non-redundant proteins generated by PISCES for the given parameters.
    @type i : string (file location)
    @param locForResults: The location where the results of the comparison should be written out.
    @type locForResults : string (file location)
    @param dirPISCES: The location of the directory that contains all of the culled lists generated by PISCES for all of the parameters.
    @type dirPISCES : string (directory location)
    @param duplicates: The location of the file containing the information about representative PDB chains (as determined by PISCES).
    @type duplicates : string (file location)
    @param resolutionData: The location of the file containing information about resolution and R Value for the chains.
    @type resolutionData : string (file location)
    @param fastaSequences: The file containing all the chains in the PDB in FASTA format.
    @type fastaSequences : string (file location)
    @param alignmentFile: The file containing the alignments for all the representative chains in the PDB (as calculated by PISCES).
    @type alignmentFile : string (file location)
    @param minLength: The minimum length that a protein chain can have (in terms of number of amino acids).
    @type minLength : integer
    @param maxLength: The maximum length that a protein chain can have (in terms of number of amino acids).
    @type maxLength : integer

    """

    resultsFile = open(locForResults, 'a')

    # The name of the PISCES file gives informaiton such as the number of proteins in the non-redundant dataset, resolution and R Value.
    chunks = i.split('_')
    numberPISCESProteinsKept = int(chunks[-1][6:-3])  # The number of proteins kept by PISCES.
    seqIdenThreshold = int(chunks[1][2:])  # The percentage cutoff used.
    resolutionLimit = float(chunks[2][3:])  # The maximum resolution permitted.
    RFactorLimit = float(chunks[3][1:])  # The maximum R Value permitted.
    # Determine whether non-XRay structures were allowed, and whether structures containing only alpha carbons were allowed.
    if len(chunks) == 7:
        inclNotXray = True
        inclCAOnly = False
    elif len(chunks) == 8:
        inclNotXray = True
        inclCAOnly = True
    else:
        inclNotXray = False
        inclCAOnly = False

    # Extract resolution, alignment, representative and length information for all of the PDB chains.
    resolutionInfo = process_resolution(resolutionData)
    alignments = process_alignments(alignmentFile, seqIdenThreshold)
    redundant = process_redundant(duplicates)
    lengths = process_fasta(fastaSequences)

    print 'Now working on file: ', i

    validProteins = []  # The proteins that are valid for the parameter constraints (resolution, R Value etc.).

    # Go through resolution and select the identifiers of the proteins that meet the structural requirements.
    for p in lengths.keys():
        proteinResolution = resolutionInfo[p]['Resolution']
        proteinRFactor = resolutionInfo[p]['RFactor']
        proteinFreeRFactor = resolutionInfo[p]['FreeRFactor']
        if not inclNotXray:
            # If non-Xray structures are not being included:
            if resolutionInfo[p]['Experiment'] != 'XRAY' or proteinResolution == 'NA':
                # If the protein structure was not determined by Xray or the resolution is not known, then don't include it
                continue
        else:
            if resolutionInfo[p]['Experiment'] != 'XRAY':
                # If non-Xray structures are being included and the protein structure was not determined by Xray, then include it.
                proteinResolution = 'NA'
                proteinRFactor = 'NA'
                proteinFreeRFactor = 'NA'
        if not inclCAOnly and resolutionInfo[p]['CAOnly'] == 'yes':
            # If the structure is only CA, and that type of structure is not being considered, then don't include it.
            continue
        
        if proteinResolution != 'NA' and float(proteinResolution) > resolutionLimit:
            continue
        if lengths[p] < minLength or lengths[p] > maxLength:
            continue
        if proteinRFactor == 'NA':
            if not inclNotXray:
                continue
        elif float(proteinRFactor) > RFactorLimit:
            continue
        
        validProteins.append(p)

    # Free up memory used by the resolution and length dicts.
    del resolutionInfo
    del lengths
    
    # Go through the list of proteins that meet the structural requirements and remove all that can be
    # replaced by a representative sequence. Add the representative to the list if not already in the list.
    nonRedundantProteins = set([])
    for p in validProteins:
        if redundant.has_key(p):
            nonRedundantProteins.add(redundant[p])
        else:
            nonRedundantProteins.add(p)

    # Free up memory used by the redundant dict.
    del redundant
    
    # Go through the alignments and record all alignments for the proteins that remain.
    proteinNames = []
    similarProteins = []
    singletonProteins = []
    for p in nonRedundantProteins:
        singleton = True
        if alignments.has_key(p):
            # If there are alignments involving p then record the ones that involve other proteins in nonRedundantProteins.
            for h in alignments[p]:
                if h in nonRedundantProteins and alignments[p][h] > seqIdenThreshold:
                    singleton = False
                    # If the two proteins are too similar then record this.
                    proteinNames.append(p)
                    proteinNames.append(h)
                    similarProteins.append(tuple(sorted([p, h])))
        if singleton:
            singletonProteins.append(p)

    # Free up memory used by the alignments dict.
    del alignments
    
    proteinNames = list(set(proteinNames))
    proteinNames.sort()
    similarProteins = list(set(similarProteins))
    indexDict = dict((proteinNames[x], x) for x in range(len(proteinNames)))

    # Create the sparse matrix.
    adjacent = sparsematrix.sparse_matrix(len(proteinNames))
    xValues = [indexDict[x] for (x,y) in similarProteins]
    yValues = [indexDict[y] for (x,y) in similarProteins]
    adjacent.addlist(xValues, yValues)
    adjacent.addlist(yValues, xValues)

    # Perform the culling by Leaf.
    removedLeaf, proteinsToKeep, removeNode, nodesToKeep, timeTaken = CMLeaf.main(adjacent, proteinNames)

    # Calculate and record the improvement of Leaf over PISCES.
    numberLeafProteinsKept = len(nonRedundantProteins) - len(removedLeaf)
    percentageImprovementLeaf = (float((numberLeafProteinsKept - numberPISCESProteinsKept)) / numberPISCESProteinsKept) * 100
    resultsFile.write(i + '\t' + str(numberPISCESProteinsKept) + '\t' + str(numberLeafProteinsKept) + '\t' + str(percentageImprovementLeaf) + '\t' +
                      str(numOfNodes) + '\t' + str(maxDegree) + '\t' + str(meanDegree) + '\n')
    resultsFile.close()

def process_redundant(duplicates):
    """Parse the file of represetnative chains.

    @param duplicates: A file recording a mapping of non-representative to representative PDB chains.
    @type duplicates : string (file location)
    return @type: dictionary
    return @use : A mapping of non-representative to representative PDB chains.

    """
    
    redundant = {}
    
    readRedundant = open(duplicates, 'r')
    for line in readRedundant:
        chunks = line.split()
        if len(chunks) == 3 and chunks[1] == 'by':
            redundantProt = chunks[0]
            representativeProt = chunks[2]
            redundant[redundantProt] = representativeProt
    readRedundant.close()
    
    return redundant

def process_fasta(fastaSequences):
    """Parse the file containing all the protein chains in the PDB.

    @param fastaSequences: A file containing the protein chains in the PDB in FASTA format.
    @type fastaSequences : string (file location)
    return @type: dictionary
    return @use : A mapping of protein chain identifier to the length of the protein chain.

    """

    lengths = {}
    
    readFasta = open(fastaSequences, 'r')
    for line in readFasta:
        if line[0] == '>':
            chunks = line.split()
            protein = chunks[0][1:]
            lengths[protein] = int(chunks[1])
    readFasta.close()
    
    return lengths

def process_resolution(resolutionData):
    """Parse the file containing the strucutral information about the PDB chains.

    @param resolutionData: The file containing the strucutral information about the PDB chains.
    @type resolutionData : string (file location)
    return @type: dictionary
    return @use : A mapping of protein chains to a dictionary containing the strucutral information about the chain.

    """

    resolutionInfo = {}
    
    readResolution = open(resolutionData, 'r')
    for line in readResolution:
        chunks = line.split()
        protein = chunks[0]
        resolutionInfo[protein] = {}
        resolutionInfo[protein]['Experiment'] = chunks[1]
        resolutionInfo[protein]['Resolution'] = chunks[2]
        resolutionInfo[protein]['RFactor'] = chunks[3]
        resolutionInfo[protein]['FreeRFactor'] = chunks[4]
        resolutionInfo[protein]['CAOnly'] = chunks[5]
    readResolution.close()
    
    return resolutionInfo

def process_alignments(alignmentFile, seqIdenThreshold):
    """Parse the file containing the information about the alignments between the protein chains in the PDB.

    @param alignmentFile: The file containing the information about the alignments between every protein chains in the PDB (as calculated by PISCES).
    @type alignmentFile : string (file location)
    @param seqIdenThreshold: The maximum percentage sequence identity permitted. Only alignments with sequence identity greater than this are returned.
    @type seqIdenThreshold : integer
    return @type: dictionary
    return @use : A record of all alignments between PDB chains.

    """

    alignments = {}
    
    alignFile = open(alignmentFile, 'r')
    for line in alignFile:
        chunks = line.split()
        query = chunks[0]
        hit = chunks[1]
        if query == hit:
            continue
        identity = float(chunks[2])
        if identity <= seqIdenThreshold:
            continue
        
        if not alignments.has_key(query):
            alignments[query] = {}
            
        if not alignments.has_key(hit):
            alignments[hit] = {}
            alignments[hit][query] = 0
        elif not alignments[hit].has_key(query):
            alignments[hit][query] = 0
        
        # The similarity is set to be the maximum of the two possible similarities (i.e. [query][hit] and [hit][query]
        maxIdentity = max(identity, alignments[hit][query])
        alignments[query][hit] = maxIdentity
        alignments[hit][query] = maxIdentity
    alignFile.close()
    
    return alignments


if __name__ == '__main__':
    """Test Leaf against PISCES on the culled lists downloaded from the PISCES website.

    Takes two command line arguments.
    The first argument is the location of the directory containing the files from PISCES which record informaiton about resolution, similarities etc.
    The second is the location of the directory containing all the gzipped culled PISCES lists.
    For more information about the required directory strucutre see the README.

    """

    # Determine the locations of the PISCES files needed.
    BLASTDBFolder = sys.argv[1]
    duplicates = BLASTDBFolder + '\MakeNonRedundant.log.pdb'
    resolutionData = BLASTDBFolder + '\\resolution.dat'
    fastaSequences = BLASTDBFolder + '\\pdbaa'
    alignmentFile = BLASTDBFolder + '\\pdbaa.align'

    
    culledListFolder = sys.argv[2]  # Expects this input to be a folder that contains all the gzipped culled PISCES lists.
    resultsFile = culledListFolder + '\Results.txt'

    # Determine whether any files have already been run, enables you to continue from where you left off.
    alreadyDone = []
    if os.path.isfile(resultsFile):
        readResults = open(resultsFile, 'r')
        for line in readResults:
            chunks = line.split()
            if chunks[0] == 'File':
                continue
            else:
                alreadyDone.append(chunks[0])
        readResults.close()
    else:
        writeResults = open(resultsFile, 'w')
        writeResults.write('File\tPISCES kept\tLeaf kept\t% improvement\tNumber of Nodes\tMax Degree\tMean Degree\n')
        writeResults.close()
    
    culledListsPISCES = os.listdir(culledListFolder)
    stillToDo = [i for i in culledListsPISCES if 'gz' in i]
    print len(stillToDo)
    stillToDo = [i for i in stillToDo if i not in alreadyDone]
    print len(stillToDo)

    # Compare all the culled lists to the non-redundant dataset that Leaf would generate.
    for i in stillToDo:
        main(i, resultsFile, culledListFolder, duplicates, resolutionData, fastaSequences, alignmentFile)
